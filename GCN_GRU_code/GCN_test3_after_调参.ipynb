{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.11250000e+01, 1.13056002e+01, 1.08332996e+01, 1.10972004e+01,\n",
       "         4.11902845e+08],\n",
       "        [1.49099998e+01, 1.52900000e+01, 1.45000000e+01, 1.45400000e+01,\n",
       "         6.56083570e+08],\n",
       "        [7.99383020e+00, 7.99383020e+00, 7.99383020e+00, 7.99383020e+00,\n",
       "         0.00000000e+00],\n",
       "        ...,\n",
       "        [3.21000004e+00, 3.21000004e+00, 2.94000006e+00, 2.94000006e+00,\n",
       "         9.15325140e+07],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[1.09582996e+01, 1.13818998e+01, 1.07986002e+01, 1.10068998e+01,\n",
       "         3.11964681e+08],\n",
       "        [1.43599997e+01, 1.49899998e+01, 1.40500002e+01, 1.46000004e+01,\n",
       "         3.34634683e+08],\n",
       "        [7.99383020e+00, 7.99383020e+00, 7.99383020e+00, 7.99383020e+00,\n",
       "         0.00000000e+00],\n",
       "        ...,\n",
       "        [3.30332994e+00, 3.45667005e+00, 3.23333001e+00, 3.35999990e+00,\n",
       "         1.69487109e+08],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[1.07500000e+01, 1.09931002e+01, 1.06250000e+01, 1.08056002e+01,\n",
       "         2.44817376e+08],\n",
       "        [1.42299995e+01, 1.45000000e+01, 1.40000000e+01, 1.42600002e+01,\n",
       "         2.64205133e+08],\n",
       "        [8.22840023e+00, 8.77159977e+00, 8.22840023e+00, 8.56789970e+00,\n",
       "         1.17942057e+08],\n",
       "        ...,\n",
       "        [3.41667008e+00, 3.56332994e+00, 3.23000002e+00, 3.28332996e+00,\n",
       "         1.24705686e+08],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.86000004e+01, 1.91000004e+01, 1.84400005e+01, 1.91000004e+01,\n",
       "         1.55421643e+08],\n",
       "        [2.77800007e+01, 2.83999996e+01, 2.75200005e+01, 2.83999996e+01,\n",
       "         1.46844133e+08],\n",
       "        [7.78999996e+00, 7.92999983e+00, 7.46999979e+00, 7.51999998e+00,\n",
       "         8.14542360e+07],\n",
       "        ...,\n",
       "        [6.53000021e+00, 6.78999996e+00, 6.15999985e+00, 6.28000021e+00,\n",
       "         7.65332022e+08],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[1.93400002e+01, 1.95799999e+01, 1.90200005e+01, 1.92099991e+01,\n",
       "         9.24503430e+07],\n",
       "        [2.87000008e+01, 2.87999992e+01, 2.82399998e+01, 2.82900009e+01,\n",
       "         6.51991110e+07],\n",
       "        [7.53000021e+00, 7.73000002e+00, 7.48000002e+00, 7.57000017e+00,\n",
       "         6.11874610e+07],\n",
       "        ...,\n",
       "        [6.25000000e+00, 6.38000011e+00, 5.80999994e+00, 5.82999992e+00,\n",
       "         7.35785546e+08],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[1.86000004e+01, 1.91000004e+01, 1.84400005e+01, 1.91000004e+01,\n",
       "         1.55421643e+08],\n",
       "        [2.77800007e+01, 2.83999996e+01, 2.75200005e+01, 2.83999996e+01,\n",
       "         1.46844133e+08],\n",
       "        [7.78999996e+00, 7.92999983e+00, 7.46999979e+00, 7.51999998e+00,\n",
       "         8.14542360e+07],\n",
       "        ...,\n",
       "        [6.53000021e+00, 6.78999996e+00, 6.15999985e+00, 6.28000021e+00,\n",
       "         7.65332022e+08],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = np.load('stock_price_matrix_adjust.npy')\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 299, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 299, 118)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technique_indicator = np.load('technique_indicator.npy',allow_pickle=True)\n",
    "technique_indicator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 299, 123)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = np.concatenate((sample_data,technique_indicator),axis=2)\n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 297, 123)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_sample_data=sample_data.copy()\n",
    "ad_sample_data = ad_sample_data[:,:-2,:]\n",
    "ad_sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#填补空值\n",
    "ad_sample_data[pd.isna(ad_sample_data)] = 5\n",
    "ad_sample_data = ad_sample_data[163:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 297, 123)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#close, high, low, open, volume,118technique_indicator\n",
    "ad_sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 297)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label的数据\n",
    "Label_data = ad_sample_data[:,:,0]\n",
    "Label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label_data\n",
    "Label_data_fixed = np.zeros((Label_data.shape[0],Label_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Label_data.shape[0]-1):\n",
    "    for j in range(Label_data.shape[1]):\n",
    "        Label_data_fixed[i+1][j]=Label_data[i+1][j]-Label_data[i][j]\n",
    "#         Label_data_fixed[i+1][j]=Label_data_fixed[i+1][j]/abs(Label_data_fixed[i+1][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(Label_data.shape[0]-1):\n",
    "    for j in range(Label_data.shape[1]):\n",
    "        if Label_data_fixed[i+1][j]>0:\n",
    "            Label_data_fixed[i+1][j]=1\n",
    "        else:\n",
    "            Label_data_fixed[i+1][j]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  287  288  289  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     1.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  ...  0.0  0.0  1.0   \n",
       "2     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  1.0  0.0   \n",
       "3     1.0  1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0  1.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1295  1.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
       "1296  1.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  1.0  1.0   \n",
       "1297  0.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  ...  1.0  1.0  0.0   \n",
       "1298  1.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  1.0   \n",
       "1299  0.0  0.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  ...  1.0  1.0  0.0   \n",
       "\n",
       "      290  291  292  293  294  295  296  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  1.0  1.0  0.0  1.0  0.0  1.0  \n",
       "2     0.0  0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     0.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1295  1.0  0.0  0.0  1.0  0.0  1.0  1.0  \n",
       "1296  1.0  0.0  0.0  1.0  1.0  1.0  1.0  \n",
       "1297  1.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "1298  0.0  1.0  1.0  1.0  0.0  1.0  0.0  \n",
       "1299  1.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "\n",
       "[1300 rows x 297 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Label_data_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(Label_date_fixed)\n",
    "Label_data_fixed=np.nan_to_num(Label_data_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 297)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_data_fixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296, 297)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_data_2 = Label_data_fixed[p-1:,:]\n",
    "Label_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 297, 122)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input 部分\n",
    "input_data = ad_sample_data[:,:,1:]\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296, 5, 297, 122)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_final = np.zeros((input_data.shape[0]+1-p,p,input_data.shape[1],input_data.shape[2]))\n",
    "input_data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 297, 122)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_final[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_data.shape[0]+1-p):\n",
    "    one_line = []\n",
    "    for j in range(p):\n",
    "        one_line.append(input_data[i+j])\n",
    "        \n",
    "    input_data_final[i] = np.array(one_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1296, 5, 297, 122)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input 部分\n",
    "input_data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=297\n",
    "M=1296\n",
    "P=5\n",
    "F=122\n",
    "TEST_SIZE = 0.3 # the test and val size of dataset\n",
    "RANDOM_STATE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 297)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.load('shareholding_relation_adjacent_matrix_tongyi.npy')\n",
    "T=T[:-2,:-2]\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 297)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I= np.load('stock_topic_share_graph.npy')\n",
    "I=I[:-2,:-2]\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 297)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=np.load('Pearson_stock_price.npy')\n",
    "S=S[:-2,:-2]\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = np.random.normal(size=(N,N))\n",
    "# I = np.random.normal(size=(N,N))\n",
    "# S = np.random.normal(size=(N,N))\n",
    "# I=T\n",
    "# S=T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fixed_Matrices = [S,I,T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = input_data_final#np.random.normal(size=(M, P, N, F))\n",
    "labels = Label_data_2#np.random.normal(size=(M, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(907, 5, 297, 122) (907, 297)\n",
      "(260, 5, 297, 122) (260, 297)\n",
      "(129, 5, 297, 122) (129, 297)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(samples, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.33, random_state=RANDOM_STATE)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.constant(x_train,dtype=tf.float32)\n",
    "y_train = tf.constant(y_train,dtype=tf.float32)\n",
    "x_test = tf.constant(x_test,dtype=tf.float32)\n",
    "y_test = tf.constant(y_test,dtype=tf.float32)\n",
    "x_val = tf.constant(x_val,dtype=tf.float32)\n",
    "y_val= tf.constant(y_val,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCGRU(tf.keras.Model):\n",
    "    def __init__(self, N, F, Units_GCN, Units_GRU, Units_FC,\n",
    "                 Fixed_Matrices, Matrix_Weights, Is_Dyn,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros'):\n",
    "        super(GCGRU, self).__init__()\n",
    "        # Number of Nodes\n",
    "        self.N = N\n",
    "        # the number of input features\n",
    "        self.F = F\n",
    "        # pre-defined matrices: shape=[(N,N),(N,N),(N,N)]\n",
    "        self.mat = Fixed_Matrices\n",
    "        # Dynamic Matrix:shape=(N,N)\n",
    "        self.dyn = self.add_weight(name='w_Dynamic', shape=(self.N, self.N),\n",
    "                                 initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                                 trainable=True)\n",
    "\n",
    "        \n",
    "        if Is_Dyn:\n",
    "            self.mats = self.dyn\n",
    "        else:\n",
    "            self.mats = self.add_weight(name='w_Matrices', shape=(self.N, self.N),\n",
    "                                        initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                                        trainable=True)\n",
    "            for i in range(len(Matrix_Weights)):\n",
    "                coe = tf.Variable(1.0,trainable=True)\n",
    "                self.mats = self.mats + Matrix_Weights[i]*self.mat[i]*coe\n",
    "        \n",
    "        # GCN_Weights\n",
    "        self.units_gcn = Units_GCN\n",
    "        self.w_gcn = []\n",
    "        self.b_gcn = []\n",
    "        pre = self.F\n",
    "        for i in range(len(self.units_gcn)):\n",
    "            aft = self.units_gcn[i]\n",
    "            w = self.add_weight(name='w_GCN', shape=(pre, aft),\n",
    "                                initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                                trainable=True)\n",
    "            self.w_gcn.append(w)\n",
    "            b = self.add_weight('b_GCN',shape=(aft,),\n",
    "                                initializer=tf.keras.initializers.get(bias_initializer),\n",
    "                                trainable=True)\n",
    "            self.b_gcn.append(b)\n",
    "            pre = aft\n",
    "        # GRU_Weights\n",
    "        self.units_gru = Units_GRU\n",
    "        self.w_gru = []\n",
    "        self.b_gru = []\n",
    "        # the number of output features of Multi-GCN\n",
    "        C = self.units_gcn[-1]\n",
    "        F = self.F\n",
    "        for i in range(len(self.units_gru)-1):\n",
    "            H = self.units_gru[i]\n",
    "            pre = F+C+H\n",
    "            aft = H\n",
    "            for j in range(3):\n",
    "                w = self.add_weight(name='w_GRU', shape=(pre,aft),\n",
    "                                    initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                                    trainable=True)\n",
    "                self.w_gru.append(w)\n",
    "                b = self.add_weight(name='b_GRU', shape=(aft,),\n",
    "                                    initializer=tf.keras.initializers.get(bias_initializer),\n",
    "                                    trainable=True)\n",
    "                self.b_gru.append(b)\n",
    "            F = aft\n",
    "        # the last layer weights\n",
    "        H = self.units_gru[-2]\n",
    "        G = self.units_gru[-1]\n",
    "        w = self.add_weight(name='w_GRU', shape=(H,G),\n",
    "                            initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                            trainable=True)\n",
    "        \n",
    "        self.w_gru.append(w)\n",
    "        b = self.add_weight(name='b_GRU', shape=(G,),\n",
    "                                 initializer=tf.keras.initializers.get(bias_initializer),\n",
    "                                 trainable=True)\n",
    "        self.b_gru.append(b)\n",
    "        \n",
    "        # FC_weights\n",
    "        self.units_fc = Units_FC\n",
    "        self.w_fc = []\n",
    "        self.b_fc = []\n",
    "        pre = G\n",
    "        for i in range(len(self.units_fc)):\n",
    "            aft = self.units_fc[i]\n",
    "            w = self.add_weight(name='w_FC', shape=(pre,aft),\n",
    "                                initializer=tf.keras.initializers.get(kernel_initializer),\n",
    "                                trainable=True)\n",
    "            self.w_fc.append(w)\n",
    "            b = self.add_weight(name='b_FC', shape=(aft,),\n",
    "                                initializer=tf.keras.initializers.get(bias_initializer),\n",
    "                                trainable=True)\n",
    "            self.b_fc.append(b)\n",
    "            pre = aft\n",
    "    \n",
    "    def Multi_GCN(self, inputs):\n",
    "        '''\n",
    "        inputs:shape=(None,P,N,F)\n",
    "        x_gcn:shape=(None,P,N,C)\n",
    "        '''\n",
    "        P = inputs.shape[1]\n",
    "        x_gcn = []\n",
    "        for t in range(P):\n",
    "            # (None, P, N, F) =>(None, N, F)\n",
    "            xt_gcn = inputs[:,t,:,:]\n",
    "            \n",
    "            # (N,N)*(None, N, F)*(F,C)=> (None, N, C)\n",
    "            for i in range(len(self.units_gcn)):\n",
    "                xt_gcn = self.mats @ xt_gcn @ self.w_gcn[i] + self.b_gcn[i]\n",
    "                xt_gcn = tf.nn.tanh(xt_gcn)\n",
    "            x_gcn.append(xt_gcn)\n",
    "        # (None,P,N,C)\n",
    "        x_gcn = tf.stack(x_gcn, axis=1)\n",
    "        return x_gcn\n",
    "    \n",
    "    def GRU(self, x, x_gcn):\n",
    "        '''\n",
    "        x:shape=(None,P,N,F)\n",
    "        x_gcn:shape=(None,N,C)\n",
    "        x_gru:shape=(None,N,G)\n",
    "        '''\n",
    "        # initialize the hidden state in each gru layer\n",
    "        h_gru = []\n",
    "        # (None, P, N, F)=>(None, N, F)*(F,H)=> (None, N, H)\n",
    "        for i in range(len(self.units_gru)-1):\n",
    "            H = self.units_gru[i]\n",
    "            h = tf.zeros_like(x[:,0,:,:], dtype=tf.float32) @ tf.zeros([F, H])\n",
    "            h_gru.append(h)\n",
    "        \n",
    "        # all gru layers at each time step\n",
    "        for t in range(P):\n",
    "            # (None, P, N, C) =>(None, N, C)\n",
    "            xt_gcn = x_gcn[:,t,:,:]\n",
    "            # (None, P, N, F) =>(None, N, F)\n",
    "            xt = x[:,t,:,:]\n",
    "\n",
    "            # the i_th layer\n",
    "            for i in range(len(h_gru)):\n",
    "                #(None, N, H)\n",
    "                ht_1 = h_gru[i]\n",
    "                #(None, N, F)+(None, N, C)+(None, N, H)=> (None, N, C+F+H)\n",
    "                x_tgh = tf.concat([xt,xt_gcn,ht_1], axis=2)\n",
    "                #(None, N, C+F+H)=> (None, N, H)\n",
    "                ut = tf.nn.sigmoid(x_tgh @ self.w_gru[3*i+0] + self.b_gru[3*i+0])\n",
    "                rt =  tf.nn.sigmoid(x_tgh @ self.w_gru[3*i+1] + self.b_gru[3*i+1])\n",
    "                \n",
    "                # (None, N, C+F+H)\n",
    "                x_tghr = tf.concat([xt, xt_gcn, tf.multiply(rt, ht_1)], axis=2)\n",
    "                \n",
    "                # (None, N, H)\n",
    "                ct = tf.nn.tanh(x_tghr @ self.w_gru[3*i+2] + self.b_gru[3*i+2])\n",
    "                # (None, N, H)\n",
    "                ht = tf.multiply(ut, ht_1) + tf.multiply((1-ut), ct)\n",
    "                # (None, N, H)\n",
    "                xt = ht\n",
    "                # (None, N, H)\n",
    "                h_gru[i]=ht\n",
    "        # the last layer\n",
    "        x_gru = tf.nn.sigmoid(ht @ self.w_gru[-1] + self.b_gru[-1])\n",
    "        return x_gru\n",
    "    \n",
    "    def FC(self, x_gru):\n",
    "        '''\n",
    "        x_gru:shape=(None, N, G)\n",
    "        outputs:shape=(None,N,1)\n",
    "        '''\n",
    "        x = x_gru\n",
    "        for i in range(len(self.w_fc)):\n",
    "            x = x @ self.w_fc[i] + self.b_fc[i]\n",
    "            x = tf.nn.sigmoid(x)\n",
    "        # (None, N)\n",
    "        x_fc = tf.squeeze(x, axis=-1)\n",
    "        return x_fc\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        inputs:shape=(None,P,N,F)\n",
    "        x_fc:shape=(None,N)\n",
    "        '''\n",
    "        # (None,P,N,C)\n",
    "        x_gcn = self.Multi_GCN(inputs)\n",
    "        # (None,N,G)\n",
    "        x_gru = self.GRU(inputs, x_gcn)\n",
    "        # (None,N)\n",
    "        x_fc = self.FC(x_gru)\n",
    "        return x_fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gcgru_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Total params: 103,154\n",
      "Trainable params: 103,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Units_GCN = [16,32,64]\n",
    "Units_GRU = [16,32]\n",
    "Units_FC = [1]\n",
    "Matrix_Weights = [1,1,1]\n",
    "Is_Dyn=False\n",
    "    \n",
    "model = GCGRU(N, F, Units_GCN, Units_GRU, Units_FC, Fixed_Matrices, Matrix_Weights,Is_Dyn)\n",
    "model.build(input_shape=(None, P, N, F))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = './500-GCGRU4',\n",
    "    monitor ='val_binary_accuracy',\n",
    "    save_weights_only = True,\n",
    "    save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['w_Dynamic:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['w_Dynamic:0'] when minimizing the loss.\n",
      "29/29 [==============================] - 10s 230ms/step - loss: nan - binary_accuracy: 0.5284 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 6s 202ms/step - loss: nan - binary_accuracy: 0.5262 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 6s 206ms/step - loss: nan - binary_accuracy: 0.5425 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 6s 223ms/step - loss: nan - binary_accuracy: 0.5443 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 6s 208ms/step - loss: nan - binary_accuracy: 0.5348 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 6s 206ms/step - loss: nan - binary_accuracy: 0.5420 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 6s 213ms/step - loss: nan - binary_accuracy: 0.5281 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 6s 210ms/step - loss: nan - binary_accuracy: 0.5466 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 6s 209ms/step - loss: nan - binary_accuracy: 0.5371 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 6s 206ms/step - loss: nan - binary_accuracy: 0.5381 - val_loss: nan - val_binary_accuracy: 0.5442\n",
      "9/9 [==============================] - 1s 82ms/step - loss: nan - binary_accuracy: 0.5647\n",
      "[nan, 0.5647242069244385]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epochs = 10\n",
    "Batch_size =32\n",
    "History = model.fit(x_train, y_train, batch_size=Batch_size, epochs=Epochs, callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n",
    "\n",
    "# Overfitting Observation\n",
    "loss = History.history['loss']\n",
    "val_loss = History.history['val_loss']\n",
    "E = [i for i in range(Epochs)]\n",
    "plt.plot(E, loss,'b-',label='loss')\n",
    "plt.plot(E, val_loss,'r-',label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('Loss VS Val_loss')\n",
    "\n",
    "# Prediction\n",
    "model.load_weights('./500-GCGRU4')\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6767670512199402, 0.5437079071998596]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.6703451871871948, 0.5436618328094482]\n",
    "[0.6767670512199402, 0.5437079071998596]\n",
    "[nan, 0.5647242069244385]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
